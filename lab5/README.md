## Лабораторная работа 5 — Множественная линейная регрессия (Jupyter Notebook)

Этот файл описывает шаги в `lab5/lab5.ipynb`: что делается, зачем это нужно и как интерпретировать результаты. Логика соответствует Excel (Сервис → Анализ данных → Регрессия), но реализована на Python.

## 1. Исходные данные
- Формируется таблица наблюдений с колонками: `t`, `tx1`, `tx2`, `tx3`, `ty`.
- Цель: построить модель множественной регрессии \( ty = a_0 + a_1 tx1 + a_2 tx2 + a_3 tx3 + \varepsilon \).

## 2. Точечные графики ty от каждого признака
- Три scatter-графика: `ty` vs `tx1`, `ty` vs `tx2`, `ty` vs `tx3`.
- Зачем: визуально оценить форму связи, выбросы, возможные нелинейности.

## 3. Линии тренда и предварительная оценка знаков/величин
- Для каждой парной зависимости строится линейный тренд и печатаются оценки \(\hat a_0, \hat a_1\) из простой регрессии.
- Зачем: сформировать ожидания по знакам и порядкам величин коэффициентов в полной модели.

## 4. Множественная регрессия (аналог Excel)
- Модель: `ty ~ tx1 + tx2 + tx3` (с константой).
- Выводятся «Regression Statistics» (Multiple R, R Square, Adjusted R Square, Standard Error, Observations), ANOVA, таблица коэффициентов (Coefficient, Std Error, t-Stat, P-value, 95%-интервалы).
- Если `statsmodels` недоступен — используется корректный ручной OLS-расчёт c близкими метриками.

## 5. Критические значения Стьюдента
- Считаются односторонние \( t_\gamma \) для \( \text{df} = T - M - 1 \) и уровней \(\gamma\in\{0.90,0.95,0.99\}\).
- Зачем: для последующих t‑проверок значимости коэффициентов.

## 6. Проверка значимости коэффициентов (t‑тесты)
- Берутся t‑статистики всех коэффициентов и сравниваются с двусторонними критическими \( t_{(1+\gamma)/2,\,T-M-1} \).
- Вывод: «значим/не значим» для \(\gamma=0.90,0.95,0.99\).

## 7. Доверительные интервалы коэффициентов
- Для каждого коэффициента строятся интервалы: \([\hat a_j \pm t_{(1+\gamma)/2}\cdot se(\hat a_j)]\) при df = \(T-M-1\).
- Уровни: 0.90, 0.95, 0.99.

## 8. Нормированный R² и адекватность модели
- Считается Adjusted R² и печатается краткое заключение по порогам: ≥0.70 — высокая, 0.50–0.70 — умеренная, <0.50 — низкая объясняющая способность.

## 9. Критические значения Фишера
- Считаются верхние квантили \( F_{\gamma;(M,\,T-M-1)} \) для \(\gamma=0.90,0.95,0.99\).
- Зачем: для F‑проверки значимости всей модели (R²).

## 10. Проверка значимости R² (F‑тест)
- Вычисляется наблюдаемое \(F\) и сравнивается с критическими \( F_{\gamma;(M,\,T-M-1)} \).
- Вывод: «значим/не значим» для каждого \(\gamma\).

## 11. Графики фактических и предсказанных значений
- Строятся графики `ty` и `ŷ` как функции каждой переменной `tx1`, `tx2`, `tx3`.
- Зачем: увидеть, насколько предсказания следуют за реальными значениями вдоль каждой оси признаков.

## 12. Анализ остатков
- Строятся scatter-графики остатков `e` против `tx1`, `tx2`, `tx3` с линией `e=0`.
- При наличии `scipy`: тест Шапиро–Уилка и QQ‑plot; иначе — краткая сводка по среднему/стандартному отклонению.
- Зачем: проверка предпосылок МНК (нормальность ошибок, отсутствие ярко выраженной гетероскедастичности).

## 13. Как запускать
1. Откройте `lab5/lab5.ipynb` в Jupyter/VS Code/Cursor.
2. Выполните ячейки сверху вниз (или Run All).
3. Зависимости: `pandas`, `numpy`, `matplotlib`; при наличии — `statsmodels` (желательно) и `scipy` (квантили, нормальность).

## 14. Интерпретация (кратко)
- Знаки и значимость коэффициентов показывают вклад признаков.
- Adjusted R² отражает общую адекватность (с учётом числа признаков).
- F‑тест проверяет значимость модели в целом; t‑тесты — отдельных коэффициентов.
- Анализ остатков подтверждает/опровергает корректность предпосылок модели.


